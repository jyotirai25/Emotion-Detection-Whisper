{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11089780,"sourceType":"datasetVersion","datasetId":6912589}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:22:24.878080Z","iopub.status.idle":"2025-03-19T13:22:24.878499Z","shell.execute_reply":"2025-03-19T13:22:24.878317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install openai-whisper torch soundfile gtts joblib neattext seaborn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:39:43.387498Z","iopub.execute_input":"2025-03-19T13:39:43.387864Z","iopub.status.idle":"2025-03-19T13:39:48.238848Z","shell.execute_reply.started":"2025-03-19T13:39:43.387809Z","shell.execute_reply":"2025-03-19T13:39:48.237862Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\nCollecting gtts\n  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\nCollecting neattext\n  Downloading neattext-0.1.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\nRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\nRequirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.5)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->openai-whisper) (2024.2.0)\nDownloading gTTS-2.5.4-py3-none-any.whl (29 kB)\nDownloading neattext-0.1.3-py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: neattext, gtts\nSuccessfully installed gtts-2.5.4 neattext-0.1.3\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"pip install openai-whisper torch soundfile\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:22:24.890205Z","iopub.status.idle":"2025-03-19T13:22:24.890504Z","shell.execute_reply":"2025-03-19T13:22:24.890380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from gtts import gTTS\n\n# Define the text\ntext = \"I am very happy today. This is a test for emotion detection.\"\n\n# Convert text to speech\ntts = gTTS(text, lang=\"en\")\n\n# Save the file\ntts.save(\"test_audio.wav\")\n\nprint(\"âœ… Audio file 'test_audio.wav' generated successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:39:52.701746Z","iopub.execute_input":"2025-03-19T13:39:52.702124Z","iopub.status.idle":"2025-03-19T13:39:52.990650Z","shell.execute_reply.started":"2025-03-19T13:39:52.702092Z","shell.execute_reply":"2025-03-19T13:39:52.989751Z"}},"outputs":[{"name":"stdout","text":"âœ… Audio file 'test_audio.wav' generated successfully!\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import whisper\n\n# Load Whisper model (small version to balance speed & accuracy)\nwhisper_model = whisper.load_model(\"small\")  # Options: \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n\nprint(\"Whisper model loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:39:56.747769Z","iopub.execute_input":"2025-03-19T13:39:56.748153Z","iopub.status.idle":"2025-03-19T13:40:00.848723Z","shell.execute_reply.started":"2025-03-19T13:39:56.748125Z","shell.execute_reply":"2025-03-19T13:40:00.847856Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Whisper model loaded successfully!\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"!wget -O test_audio.wav https://www2.cs.uic.edu/~i101/SoundFiles/piano2.wav\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:22:43.673895Z","iopub.execute_input":"2025-03-19T13:22:43.674327Z","iopub.status.idle":"2025-03-19T13:36:23.487236Z","shell.execute_reply.started":"2025-03-19T13:22:43.674278Z","shell.execute_reply":"2025-03-19T13:36:23.486039Z"}},"outputs":[{"name":"stdout","text":"--2025-03-19 13:22:43--  https://www2.cs.uic.edu/~i101/SoundFiles/piano2.wav\nResolving www2.cs.uic.edu (www2.cs.uic.edu)... 131.193.32.16\nConnecting to www2.cs.uic.edu (www2.cs.uic.edu)|131.193.32.16|:443... failed: Connection timed out.\nRetrying.\n\n--2025-03-19 13:24:57--  (try: 2)  https://www2.cs.uic.edu/~i101/SoundFiles/piano2.wav\nConnecting to www2.cs.uic.edu (www2.cs.uic.edu)|131.193.32.16|:443... failed: Connection timed out.\nRetrying.\n\n--2025-03-19 13:27:13--  (try: 3)  https://www2.cs.uic.edu/~i101/SoundFiles/piano2.wav\nConnecting to www2.cs.uic.edu (www2.cs.uic.edu)|131.193.32.16|:443... failed: Connection timed out.\nRetrying.\n\n--2025-03-19 13:29:29--  (try: 4)  https://www2.cs.uic.edu/~i101/SoundFiles/piano2.wav\nConnecting to www2.cs.uic.edu (www2.cs.uic.edu)|131.193.32.16|:443... failed: Connection timed out.\nRetrying.\n\n--2025-03-19 13:31:50--  (try: 5)  https://www2.cs.uic.edu/~i101/SoundFiles/piano2.wav\nConnecting to www2.cs.uic.edu (www2.cs.uic.edu)|131.193.32.16|:443... failed: Connection timed out.\nRetrying.\n\n--2025-03-19 13:34:10--  (try: 6)  https://www2.cs.uic.edu/~i101/SoundFiles/piano2.wav\nConnecting to www2.cs.uic.edu (www2.cs.uic.edu)|131.193.32.16|:443... ^C\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import whisper\n\n# Load Whisper model (small version for good balance)\nwhisper_model = whisper.load_model(\"small\")\n\nprint(\"âœ… Whisper model loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:40:04.486687Z","iopub.execute_input":"2025-03-19T13:40:04.487319Z","iopub.status.idle":"2025-03-19T13:40:08.951383Z","shell.execute_reply.started":"2025-03-19T13:40:04.487286Z","shell.execute_reply":"2025-03-19T13:40:08.950393Z"}},"outputs":[{"name":"stdout","text":"âœ… Whisper model loaded successfully!\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"def transcribe_audio(audio_path):\n    \"\"\"\n    Convert speech to text using Whisper model.\n    \"\"\"\n    result = whisper_model.transcribe(audio_path)\n    return result[\"text\"]\n\n# Transcribe the test audio\naudio_file = \"test_audio.wav\"\ntranscribed_text = transcribe_audio(audio_file)\n\nprint(\"ðŸŽ™ Transcribed Text:\", transcribed_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:40:12.151807Z","iopub.execute_input":"2025-03-19T13:40:12.152189Z","iopub.status.idle":"2025-03-19T13:40:20.960132Z","shell.execute_reply.started":"2025-03-19T13:40:12.152159Z","shell.execute_reply":"2025-03-19T13:40:20.959159Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","output_type":"stream"},{"name":"stdout","text":"ðŸŽ™ Transcribed Text:  I am very happy today. This is a test for emotion detection.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import os\n\n# Check available files in the working directory\nprint(\"Files in the working directory:\", os.listdir(\"/kaggle/working\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:45:57.127271Z","iopub.execute_input":"2025-03-19T13:45:57.127584Z","iopub.status.idle":"2025-03-19T13:45:57.132878Z","shell.execute_reply.started":"2025-03-19T13:45:57.127561Z","shell.execute_reply":"2025-03-19T13:45:57.131958Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Files in the working directory: ['.virtual_documents', 'test_audio.wav']\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import pandas as pd\nimport neattext.functions as nfx\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/emotions1/tweet_emotions.csv\")  # Update with correct dataset path\n\n# Rename columns if needed\ndf.rename(columns={'sentiment': 'Emotion', 'content': 'Text'}, inplace=True)\n\n# Filter dataset to include only happy, sad, and angry\ndf = df[df['Emotion'].isin(['happy', 'sad', 'angry'])]\n\n# Clean the text data\ndf['Clean_Text'] = df['Text'].apply(lambda x: nfx.remove_special_characters(x.lower()))\ndf['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_stopwords)\n\n# Display first few rows to verify\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:51:43.757486Z","iopub.execute_input":"2025-03-19T13:51:43.757857Z","iopub.status.idle":"2025-03-19T13:51:43.836725Z","shell.execute_reply.started":"2025-03-19T13:51:43.757799Z","shell.execute_reply":"2025-03-19T13:51:43.835898Z"}},"outputs":[{"name":"stdout","text":"Empty DataFrame\nColumns: [tweet_id, Emotion, Text, Clean_Text]\nIndex: []\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"df = df[df['Emotion'].isin(['happy', 'sad', 'angry'])]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:53:13.867479Z","iopub.execute_input":"2025-03-19T13:53:13.867796Z","iopub.status.idle":"2025-03-19T13:53:13.872625Z","shell.execute_reply.started":"2025-03-19T13:53:13.867769Z","shell.execute_reply":"2025-03-19T13:53:13.871725Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"print(\"Dataset shape BEFORE filtering:\", df.shape)  # Check data size before filtering\ndf = df[df['Emotion'].isin(['happy', 'sad', 'angry'])]\nprint(\"Dataset shape AFTER filtering:\", df.shape)   # Check data size after filtering\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:53:18.098204Z","iopub.execute_input":"2025-03-19T13:53:18.098516Z","iopub.status.idle":"2025-03-19T13:53:18.105486Z","shell.execute_reply.started":"2025-03-19T13:53:18.098492Z","shell.execute_reply":"2025-03-19T13:53:18.104582Z"}},"outputs":[{"name":"stdout","text":"Dataset shape BEFORE filtering: (0, 4)\nDataset shape AFTER filtering: (0, 4)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"print(\"Column Names:\", df.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:53:31.964911Z","iopub.execute_input":"2025-03-19T13:53:31.965274Z","iopub.status.idle":"2025-03-19T13:53:31.970570Z","shell.execute_reply.started":"2025-03-19T13:53:31.965247Z","shell.execute_reply":"2025-03-19T13:53:31.969682Z"}},"outputs":[{"name":"stdout","text":"Column Names: Index(['tweet_id', 'Emotion', 'Text', 'Clean_Text'], dtype='object')\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"df.rename(columns={'sentiment': 'Emotion', 'content': 'Text'}, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:53:48.062682Z","iopub.execute_input":"2025-03-19T13:53:48.063070Z","iopub.status.idle":"2025-03-19T13:53:48.067662Z","shell.execute_reply.started":"2025-03-19T13:53:48.063036Z","shell.execute_reply":"2025-03-19T13:53:48.066679Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"df.columns = df.columns.str.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:54:00.063220Z","iopub.execute_input":"2025-03-19T13:54:00.063550Z","iopub.status.idle":"2025-03-19T13:54:00.068211Z","shell.execute_reply.started":"2025-03-19T13:54:00.063524Z","shell.execute_reply":"2025-03-19T13:54:00.067279Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"print(\"Unique emotions:\", df['Emotion'].unique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:54:09.743137Z","iopub.execute_input":"2025-03-19T13:54:09.743453Z","iopub.status.idle":"2025-03-19T13:54:09.749650Z","shell.execute_reply.started":"2025-03-19T13:54:09.743428Z","shell.execute_reply":"2025-03-19T13:54:09.748449Z"}},"outputs":[{"name":"stdout","text":"Unique emotions: []\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"print(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:55:15.848343Z","iopub.execute_input":"2025-03-19T13:55:15.848711Z","iopub.status.idle":"2025-03-19T13:55:15.854006Z","shell.execute_reply.started":"2025-03-19T13:55:15.848680Z","shell.execute_reply":"2025-03-19T13:55:15.852954Z"}},"outputs":[{"name":"stdout","text":"Empty DataFrame\nColumns: [tweet_id, Emotion, Text, Clean_Text]\nIndex: []\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"import os\n\ndataset_path = \"/kaggle/input/emotions1/tweet_emotions.csv\"\n\n# Check if the file exists and has content\nif os.path.exists(dataset_path):\n    print(\"âœ… File found!\")\n    print(\"File size:\", os.path.getsize(dataset_path), \"bytes\")\nelse:\n    print(\"âŒ File NOT found! Check your dataset path.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:56:52.127618Z","iopub.execute_input":"2025-03-19T13:56:52.127981Z","iopub.status.idle":"2025-03-19T13:56:52.134240Z","shell.execute_reply.started":"2025-03-19T13:56:52.127951Z","shell.execute_reply":"2025-03-19T13:56:52.133411Z"}},"outputs":[{"name":"stdout","text":"âœ… File found!\nFile size: 3768210 bytes\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"with open(\"/kaggle/input/emotions1/tweet_emotions.csv\", \"r\") as file:\n    for _ in range(5):  # Read and print first 5 lines\n        print(file.readline().strip())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:58:12.553527Z","iopub.execute_input":"2025-03-19T13:58:12.553907Z","iopub.status.idle":"2025-03-19T13:58:12.560852Z","shell.execute_reply.started":"2025-03-19T13:58:12.553868Z","shell.execute_reply":"2025-03-19T13:58:12.559899Z"}},"outputs":[{"name":"stdout","text":"tweet_id,sentiment,content\n1956967341,empty,@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[\n1956967666,sadness,Layin n bed with a headache  ughhhh...waitin on your call...\n1956967696,sadness,Funeral ceremony...gloomy friday...\n1956967789,enthusiasm,wants to hang out with friends SOON!\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"import pandas as pd\n\ndataset_path = \"/kaggle/input/emotions1/tweet_emotions.csv\"\n\n# Load dataset without headers (to inspect structure)\ndf = pd.read_csv(dataset_path, header=None)\n\n# Print first few rows\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:58:23.839406Z","iopub.execute_input":"2025-03-19T13:58:23.839852Z","iopub.status.idle":"2025-03-19T13:58:23.943719Z","shell.execute_reply.started":"2025-03-19T13:58:23.839795Z","shell.execute_reply":"2025-03-19T13:58:23.942756Z"}},"outputs":[{"name":"stdout","text":"            0           1                                                  2\n0    tweet_id   sentiment                                            content\n1  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n2  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n3  1956967696     sadness                Funeral ceremony...gloomy friday...\n4  1956967789  enthusiasm               wants to hang out with friends SOON!\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"import pandas as pd\n\n# Load dataset and manually assign correct column names\ndataset_path = \"/kaggle/input/emotions1/tweet_emotions.csv\"\ndf = pd.read_csv(dataset_path, names=[\"tweet_id\", \"Emotion\", \"Text\"], skiprows=1)  # Skip first row\n\n# Display first few rows after fixing\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:59:28.238618Z","iopub.execute_input":"2025-03-19T13:59:28.238984Z","iopub.status.idle":"2025-03-19T13:59:28.324573Z","shell.execute_reply.started":"2025-03-19T13:59:28.238956Z","shell.execute_reply":"2025-03-19T13:59:28.323574Z"}},"outputs":[{"name":"stdout","text":"     tweet_id     Emotion                                               Text\n0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n2  1956967696     sadness                Funeral ceremony...gloomy friday...\n3  1956967789  enthusiasm               wants to hang out with friends SOON!\n4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"df = df[df[\"Emotion\"].isin([\"happiness\", \"sadness\", \"anger\"])]\n\n# Check unique emotions after filtering\nprint(\"Filtered unique emotions:\", df[\"Emotion\"].unique())\n\n# Display the first few rows\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:59:38.916013Z","iopub.execute_input":"2025-03-19T13:59:38.916419Z","iopub.status.idle":"2025-03-19T13:59:38.931676Z","shell.execute_reply.started":"2025-03-19T13:59:38.916389Z","shell.execute_reply":"2025-03-19T13:59:38.930882Z"}},"outputs":[{"name":"stdout","text":"Filtered unique emotions: ['sadness' 'happiness' 'anger']\n     tweet_id  Emotion                                               Text\n1  1956967666  sadness  Layin n bed with a headache  ughhhh...waitin o...\n2  1956967696  sadness                Funeral ceremony...gloomy friday...\n6  1956968487  sadness  I should be sleep, but im not! thinking about ...\n8  1956969035  sadness            @charviray Charlene my love. I miss you\n9  1956969172  sadness         @kelcouch I'm sorry  at least it's Friday?\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import make_pipeline\nimport joblib\n\n# Prepare data\nX = df['Clean_Text']\ny = df['Emotion']\n\n# Convert text to TF-IDF vectors\ntfidf = TfidfVectorizer()\nX_tfidf = tfidf.fit_transform(X)\n\n# Train a simple Naive Bayes model\nmodel = MultinomialNB()\nmodel.fit(X_tfidf, y)\n\n# Save Model and Vectorizer\njoblib.dump(model, \"/kaggle/working/emotion_model.pkl\")\njoblib.dump(tfidf, \"/kaggle/working/tfidf_vectorizer.pkl\")\n\nprint(\"âœ… Model and Vectorizer Saved Successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:59:06.867699Z","iopub.execute_input":"2025-03-19T13:59:06.868074Z","iopub.status.idle":"2025-03-19T13:59:06.906831Z","shell.execute_reply.started":"2025-03-19T13:59:06.868042Z","shell.execute_reply":"2025-03-19T13:59:06.905493Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Clean_Text'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-e0b972cdcdcf>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clean_Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Clean_Text'"],"ename":"KeyError","evalue":"'Clean_Text'","output_type":"error"}],"execution_count":69},{"cell_type":"code","source":"import joblib\nimport neattext.functions as nfx\n\n# Load trained model and vectorizer\nemotion_model = joblib.load(\"emotion_model.pkl\")\ntfidf_vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n\nprint(\"âœ… Emotion detection model loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:52:06.898308Z","iopub.execute_input":"2025-03-19T13:52:06.898622Z","iopub.status.idle":"2025-03-19T13:52:06.914401Z","shell.execute_reply.started":"2025-03-19T13:52:06.898598Z","shell.execute_reply":"2025-03-19T13:52:06.913025Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-08d3e8fdc1bf>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load trained model and vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0memotion_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emotion_model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tfidf_vectorizer.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'emotion_model.pkl'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'emotion_model.pkl'","output_type":"error"}],"execution_count":53},{"cell_type":"code","source":"def predict_emotion(text):\n    \"\"\"\n    Predict emotion from transcribed text.\n    \"\"\"\n    # Preprocess text\n    text_cleaned = nfx.remove_special_characters(text.lower())\n    text_cleaned = nfx.remove_stopwords(text_cleaned)\n    \n    # Convert to numerical features using TF-IDF\n    vectorized_text = tfidf_vectorizer.transform([text_cleaned])\n    \n    # Predict emotion\n    prediction = emotion_model.predict(vectorized_text)\n    \n    return prediction[0]\n\n# Predict emotion for transcribed text\npredicted_emotion = predict_emotion(transcribed_text)\n\nprint(\"\\nðŸŽ™ Speech-to-Text Output:\", transcribed_text)\nprint(\"ðŸ˜Š Detected Emotion:\", predicted_emotion)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:41:37.293022Z","iopub.execute_input":"2025-03-19T13:41:37.293372Z","iopub.status.idle":"2025-03-19T13:41:37.312710Z","shell.execute_reply.started":"2025-03-19T13:41:37.293346Z","shell.execute_reply":"2025-03-19T13:41:37.311494Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-acd4a4631b9c>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Predict emotion for transcribed text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpredicted_emotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscribed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸŽ™ Speech-to-Text Output:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscribed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-acd4a4631b9c>\u001b[0m in \u001b[0;36mpredict_emotion\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Convert to numerical features using TF-IDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mvectorized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_cleaned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Predict emotion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tfidf_vectorizer' is not defined"],"ename":"NameError","evalue":"name 'tfidf_vectorizer' is not defined","output_type":"error"}],"execution_count":41},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a bar chart for emotion distribution\nsns.barplot(x=[\"Happy\", \"Sad\", \"Angry\"], y=[1 if predicted_emotion == \"happy\" else 0, \n                                            1 if predicted_emotion == \"sad\" else 0, \n                                            1 if predicted_emotion == \"angry\" else 0], \n            palette=\"coolwarm\")\n\nplt.title(\"Predicted Emotion\")\nplt.xlabel(\"Emotion\")\nplt.ylabel(\"Confidence\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T13:36:23.518929Z","iopub.status.idle":"2025-03-19T13:36:23.519298Z","shell.execute_reply":"2025-03-19T13:36:23.519113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}